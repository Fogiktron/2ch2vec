{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize, RegexpTokenizer\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Утилсы: регулярки, загрузка файлов и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from re import sub, compile\n",
    "\n",
    "def cut(data):\n",
    "    r = compile(r'<.*?>|>>.*|&#(47|92);|&quot;|&gt;|(http|https):.*')\n",
    "    return r.sub('', data)\n",
    "\n",
    "def punctuate(data):\n",
    "    r = compile( r'([a-zA-Z])([,.!])', r'\\1 \\2')\n",
    "    return r.sub('', data)\n",
    "\n",
    "def pos_cut(s):\n",
    "    s = sub(r\"ADJF\", \"ADJ\", s)\n",
    "    s = sub(r\"ADVB\", \"ADV\", s)\n",
    "    s = sub(r\"INFN\", \"VERB\", s)\n",
    "    return s\n",
    "\n",
    "def topic_cut(word):\n",
    "    return sub('[^a-zA-Zа-яА-Я]', '', word)\n",
    "\n",
    "def remove_noise(s):\n",
    "    remove_noise = compile('(@[A-Za-z_0-9]+)|\\[.+]\\,|\\[.+]|([^0-9A-Za-zА-Яа-я[\\.’,?!-:] \\t])'\n",
    "                           '|(\\w+:\\/\\/\\S+)')\n",
    "    return (sub(remove_noise, '',  s))\n",
    "\n",
    "def check_for_rus_lan(word):\n",
    "    regex = compile('[А-Яа-я]+$')\n",
    "    if regex.match(word):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BOARD = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "documents = load(open('pickle/' + BOARD + '.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile = open('w2.txt', 'w')\n",
    "\n",
    "for item in documents:\n",
    "    thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Инициализация стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('russian')\n",
    "stop += stopwords.words('english')\n",
    "\n",
    "my_stop = ['весь', 'всякий', 'тот', 'это', 'самое', 'каким', 'сама', 'никак', 'она', 'она', 'оно', 'какие', 'какого', 'которая', 'многое', 'чему', 'всему', 'раза', 'сразу', 'весь', 'раз', 'пор', 'например', 'вроде', 'которые', 'который', 'просто', 'очень', 'почему', 'вообще', 'ещё', 'типа', 'ради', 'всё', 'хотя', 'тебе', 'нужно', 'пока']\n",
    "my_stop_verb = ['сделать', 'можешь', 'могу', 'могут', 'делать', 'будешь', 'быть', 'будут', 'смочь']\n",
    "\n",
    "[stop.append(morph.parse(i)[0].normal_form) for i in my_stop]\n",
    "[stop.append(morph.parse(i)[0].normal_form) for i in my_stop_verb]\n",
    "\n",
    "dvach_stop = ['такое', 'лол', 'бля']\n",
    "\n",
    "stop += dvach_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка токенизатора, токенизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alpha_tokenizer = RegexpTokenizer('[A-Za-zА-Яа-я]\\w+')\n",
    "\n",
    "def my_tokenize(sent):\n",
    "    sents = list(alpha_tokenizer.tokenize(sent))\n",
    "    return list([morph.parse(sent.lower())[0].normal_form for sent in sents if sent.lower() not in stop and len(sent.lower()) > 1])\n",
    "\n",
    "model_data = [my_tokenize(sent) for sent in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from pickle import dump\n",
    "\n",
    "subdir = 'pickle'\n",
    "if not path.exists(subdir):\n",
    "    makedirs(subdir)\n",
    "file_path = path.join(subdir, 'model_data.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as f:\n",
    "    dump(documents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обучение Word2Vec-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "corpus.fit(model_data, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сериализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from pickle import dump\n",
    "\n",
    "subdir = 'models'\n",
    "if not path.exists(subdir):\n",
    "    makedirs(subdir)\n",
    "file_path = path.join(subdir, BOARD + '_glove.pickle')\n",
    "\n",
    "with open(file_path, 'wb') as f:\n",
    "    dump(glove, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('она', 0.74974750400770906),\n",
       " ('это', 0.74152926959798227),\n",
       " ('сиська', 0.73945613742605198),\n",
       " ('любовь', 0.73912827160230721)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(morph.parse('абу')[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
