{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, Series\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "morph = MorphAnalyzer()\n",
    "alpha_tokenizer = RegexpTokenizer('[A-Za-zА-Яа-я]\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = read_csv('2ch_test_set.csv')\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('2ch_model')\n",
    "vocab = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pre_process(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokens = alpha_tokenizer.tokenize(sentence)\n",
    "    model_tokens = []\n",
    "    for index, word in enumerate(tokens):\n",
    "        lem_word = morph.parse(word.lower())[0].normal_form\n",
    "        if lem_word in vocab:\n",
    "            model_tokens.append(lem_word)\n",
    "    return model_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "old_err_state = np.seterr(all='raise')\n",
    "\n",
    "def vectorize_message(sentence, model, num_features, vocab):\n",
    "    featureVec = np.zeros((num_features), dtype='float32')\n",
    "    nwords = 0\n",
    "    \n",
    "    tokens = pre_process(sentence.lower())\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in vocab: \n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "            nwords = nwords + 1\n",
    "    try:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    except FloatingPointError:\n",
    "         featureVec = np.zeros((num_features), dtype='float32')\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vec = []\n",
    "\n",
    "for i in df.text.values:\n",
    "    vec.append(vectorize_message(i, model, 400, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CHUNK = 40\n",
    "\n",
    "X = np.array(vec)\n",
    "Y = np.array(df.is_relevent.values)\n",
    "X_train = X[:~CHUNK]\n",
    "Y_train = Y[:~CHUNK]\n",
    "X_test = X[~CHUNK:]\n",
    "Y_test = Y[~CHUNK:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75609756097560976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C = 1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "result = clf.predict(X_test)\n",
    "accuracy_score(Y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80487804878048785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 150)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "result = clf.predict(X_test)\n",
    "accuracy_score(Y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75609756097560976"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C = 0.01, kernel = 'linear')\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "result = clf.predict(X_test)\n",
    "accuracy_score(Y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array(vectorize_message('питон + генсим = годнота!', model, 400, vocab)).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array(vectorize_message('пошёл нахуй зелёный веб макакер', model, 400, vocab)).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
