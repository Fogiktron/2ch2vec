{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from nltk import download\n",
    "\n",
    "#download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: обучить модель на корпусе текстов с интернет-сленгом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('2ch.txt') as f:\\n    text = f.read().replace('\\n', '')\\n    \\nsentences = [list(tokenize(sent)) for sent in sent_tokenize(text)]\\n\\nmin_count = 1\\nsize = 50\\nwindow = 10\\n\\nmodel = Word2Vec(sentences, min_count=min_count, size=size, window=window,  workers=4)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk import sent_tokenize\n",
    "#from gensim.utils import tokenize\n",
    "#from gensim.models import *\n",
    "\n",
    "#SKIP FOR NOW\n",
    "\n",
    "'''\n",
    "with open('2ch.txt') as f:\n",
    "    text = f.read().replace('\\n', '')\n",
    "    \n",
    "sentences = [list(tokenize(sent)) for sent in sent_tokenize(text)]\n",
    "\n",
    "min_count = 1\n",
    "size = 50\n",
    "window = 10\n",
    "\n",
    "model = Word2Vec(sentences, min_count=min_count, size=size, window=window,  workers=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Утилсы: регулярки, загрузка файлов и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from re import sub, compile\n",
    "\n",
    "def cut(data):\n",
    "    r = compile(r'<.*?>|>>.*|&#(47|92);|&quot;|&gt;|(http|https):.*')\n",
    "    return r.sub('', data)\n",
    "\n",
    "def pos_cut(s):\n",
    "    s = sub(r\"ADJF\", \"ADJ\", s)\n",
    "    s = sub(r\"ADVB\", \"ADV\", s)\n",
    "    s = sub(r\"INFN\", \"VERB\", s)\n",
    "    return s\n",
    "\n",
    "def topic_cut(word):\n",
    "    return sub('[^a-zA-Zа-яА-Я]', '', word)\n",
    "\n",
    "def check_for_rus_lan(word):\n",
    "    regex = compile('[А-Яа-я]+$')\n",
    "    if regex.match(word):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка каталога тредов выбранной доски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "DVACH = 'https://2ch.hk/'\n",
    "BOARD = 'pr'\n",
    "\n",
    "dvach_page = get(DVACH + BOARD + '/catalog.json').json()\n",
    "threads = [i['num'] for i in dvach_page['threads']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка n-ного треда из списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C Programming Language #20'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = get(DVACH +  BOARD + '/res/' + threads[5] + '.json').json()\n",
    "thread['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "documents = [cut(i['comment']) for i in thread['threads'][0]['posts'] if cut(i['comment'])]\n",
    "\n",
    "texts = [[word for word in document.lower().split() if word not in stopwords.words('russian') and word.isalpha() and len(word) > 3]\n",
    "         for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "all_tokens = sum(texts, [])\n",
    "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "texts = [[word for word in text if word not in tokens_once]\n",
    "         for text in texts]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание LDA модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.256*\"сообщения\" + 0.256*\"первого\" + 0.251*\"почему\" + 0.140*\"строки\" + 0.024*\"типа\" + 0.024*\"посчитать\" + 0.024*\"return\" + 0.024*\"result\"'),\n",
       " (1,\n",
       "  '0.130*\"почему\" + 0.129*\"типа\" + 0.126*\"посчитать\" + 0.123*\"строки\" + 0.123*\"return\" + 0.123*\"первого\" + 0.123*\"сообщения\" + 0.123*\"result\"'),\n",
       " (2,\n",
       "  '0.602*\"посчитать\" + 0.059*\"почему\" + 0.058*\"типа\" + 0.056*\"строки\" + 0.056*\"сообщения\" + 0.056*\"return\" + 0.056*\"первого\" + 0.056*\"result\"'),\n",
       " (3,\n",
       "  '0.256*\"result\" + 0.255*\"return\" + 0.255*\"типа\" + 0.139*\"строки\" + 0.024*\"почему\" + 0.024*\"посчитать\" + 0.024*\"первого\" + 0.024*\"сообщения\"'),\n",
       " (4,\n",
       "  '0.452*\"типа\" + 0.081*\"почему\" + 0.079*\"посчитать\" + 0.078*\"строки\" + 0.078*\"return\" + 0.078*\"первого\" + 0.077*\"сообщения\" + 0.077*\"result\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models, corpora\n",
    "\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание LSI модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.256*\"сообщения\" + 0.256*\"первого\" + 0.251*\"почему\" + 0.140*\"строки\" + 0.024*\"типа\" + 0.024*\"посчитать\" + 0.024*\"return\" + 0.024*\"result\"'),\n",
       " (1,\n",
       "  '0.130*\"почему\" + 0.129*\"типа\" + 0.126*\"посчитать\" + 0.123*\"строки\" + 0.123*\"return\" + 0.123*\"первого\" + 0.123*\"сообщения\" + 0.123*\"result\"'),\n",
       " (2,\n",
       "  '0.602*\"посчитать\" + 0.059*\"почему\" + 0.058*\"типа\" + 0.056*\"строки\" + 0.056*\"сообщения\" + 0.056*\"return\" + 0.056*\"первого\" + 0.056*\"result\"'),\n",
       " (3,\n",
       "  '0.256*\"result\" + 0.255*\"return\" + 0.255*\"типа\" + 0.139*\"строки\" + 0.024*\"почему\" + 0.024*\"посчитать\" + 0.024*\"первого\" + 0.024*\"сообщения\"'),\n",
       " (4,\n",
       "  '0.452*\"типа\" + 0.081*\"почему\" + 0.079*\"посчитать\" + 0.078*\"строки\" + 0.078*\"return\" + 0.078*\"первого\" + 0.077*\"сообщения\" + 0.077*\"result\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=1) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus]\n",
    "lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение списка характеризующих тему слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['почему',\n",
       " 'типа',\n",
       " 'посчитать',\n",
       " 'строки',\n",
       " 'return',\n",
       " 'первого',\n",
       " 'сообщения',\n",
       " 'result']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = lda.print_topic(1)\n",
    "keywords= [topic_cut(word) for word in topics.split('+')]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка обученной модели RusVectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.KeyedVectors.load_word2vec_format('corpora.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработчик токенов для использования модели RusVectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymorphy2 \n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def process(s):\n",
    "    if not check_for_rus_lan(s):\n",
    "        return None\n",
    "    s += '_' + morph.parse(s)[0].tag.POS\n",
    "    s = pos_cut(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расстояние от слова до ключевых слов тематического кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.083447638458197956, 'посчитать']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = [[model.similarity(process('программирование'), process(keyword)), keyword] for keyword in keywords if process(keyword) in model.vocab]\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO суммарное расстояние всего сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
