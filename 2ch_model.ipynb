{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize, RegexpTokenizer\n",
    "from numpy import isnan\n",
    "from requests import get, exceptions\n",
    "from itertools import chain\n",
    "from nltk import sent_tokenize\n",
    "import pymorphy2 \n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DVACH = 'https://2ch.hk/'\n",
    "BOARD = 'pr'\n",
    "\n",
    "dvach_page = get(DVACH + BOARD + '/catalog.json').json()\n",
    "threads = [i['num'] for i in dvach_page['threads']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for every_thread in threads[:50]:\n",
    "    thread = get(DVACH +  BOARD + '/res/' + every_thread + '.json', timeout=5).json()\n",
    "    [documents.append(sent_tokenize(cut(i['comment']))) for i in thread['threads'][0]['posts'] if len(cut(i['comment'])) > 2]\n",
    "\n",
    "documents = list(chain.from_iterable(documents))\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_tokenizer = RegexpTokenizer('[A-Za-zА-Яа-я]\\w+')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def my_tokenize(sent):\n",
    "    sents = list(alpha_tokenizer.tokenize(sent))\n",
    "    return set([morph.parse(sent.lower())[0].normal_form for sent in sents if sent.lower() not in stop and len(sent.lower()) > 1])\n",
    "\n",
    "model_data = [my_tokenize(sent) for sent in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "stop += stopwords.words('english')\n",
    "my_stop = ['весь', 'всякий', 'тот', 'это', 'самое', 'каким', 'сама', 'никак', 'она', 'она', 'оно', 'какие', 'какого', 'которая', 'многое', 'чему', 'всему', 'раза', 'сразу', 'весь', 'раз', 'пор', 'например', 'вроде', 'которые', 'который', 'просто', 'очень', 'почему', 'вообще', 'ещё', 'типа', 'ради', 'всё', 'хотя', 'тебе', 'нужно', 'пока']\n",
    "my_stop_verb = ['сделать', 'можешь', 'могу', 'могут', 'делать', 'будешь', 'быть', 'будут', 'смочь']\n",
    "[stop.append(morph.parse(i)[0].normal_form) for i in my_stop]\n",
    "[stop.append(morph.parse(i)[0].normal_form) for i in my_stop_verb]\n",
    "dvach_stop = ['такое', 'лол', 'бля']\n",
    "stop += dvach_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_count = 1\n",
    "size = 600\n",
    "window = 40\n",
    "\n",
    "model = Word2Vec(model_data, min_count=min_count, size=size, window=window,  workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('быть', 0.9999947547912598),\n",
       " ('стать', 0.9999947547912598),\n",
       " ('сидеть', 0.9999947547912598),\n",
       " ('думать', 0.999994695186615),\n",
       " ('такой', 0.9999945759773254),\n",
       " ('программист', 0.9999945759773254),\n",
       " ('человек', 0.9999945163726807),\n",
       " ('работа', 0.9999944567680359),\n",
       " ('уровень', 0.9999944567680359),\n",
       " ('взять', 0.9999944567680359)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(morph.parse('галера')[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from re import sub, compile\n",
    "\n",
    "def cut(data):\n",
    "    r = compile(r'<.*?>|>>\\d*|\\(OP\\)|&#(\\d*);|&quot;|&gt;|(http|https):.*')\n",
    "    return r.sub('', punctuate_word(punctuate_sent((data))))\n",
    "\n",
    "def punctuate_sent(data):\n",
    "    r = compile(r'([a-zA-Zа-яА-Я])([.!\\?])')\n",
    "    return r.sub(r'\\1. ', data)\n",
    "\n",
    "def punctuate_word(data):\n",
    "    r = compile(r'([a-zA-Zа-яА-Я])([,])')\n",
    "    return r.sub(r'\\1, ', data)\n",
    "\n",
    "def pos_cut(s):\n",
    "    s = sub(r\"ADJF\", \"ADJ\", s)\n",
    "    s = sub(r\"ADVB\", \"ADV\", s)\n",
    "    s = sub(r\"INFN\", \"VERB\", s)\n",
    "    return s\n",
    "\n",
    "def topic_cut(word):\n",
    "    return sub('[^a-zA-Zа-яА-Я]', '', word)\n",
    "\n",
    "def check_for_rus_lan(word):\n",
    "    regex = compile('[А-Яа-я]+$')\n",
    "    if regex.match(word):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
